{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance: \n",
    "3 Epochs: 94%~ test data set accuracy\n",
    "70 Epochs: 97.8%~ test data set accuracy, 97.5% val_accuracy\n",
    "\n",
    "Model: \n",
    "- Sequential Model (5 layers)\n",
    "- Inputs 28x28 array, flattens to 784 1D array\n",
    "- 3 Dense layers, using ReLu activation 128 neurons each\n",
    "- Output Dense Layer with 10 neurons, softmax to output probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf # machine learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('./TestData/train.csv')\n",
    "x_train_dataframe = training_data.iloc[:, training_data.columns != 'label']\n",
    "x_train = x_train_dataframe.values\n",
    "y_train = training_data.label.values\n",
    "\n",
    "testing_data = pd.read_csv('./TestData/test.csv')\n",
    "\n",
    "x_test = testing_data.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing Training Data\n",
    "- You only need to normalize the x train because it's a very big range, so we total need to normalize it\n",
    "- Adjusts the values in the array so that the length of the vector (or the array) becomes 1, in terms of Euclidean norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Flatten name=flatten_1, built=True>, <Dense name=dense_4, built=True>, <Dense name=dense_5, built=True>, <Dense name=dense_6, built=True>, <Dense name=dense_7, built=True>]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "model.add(tf.keras.Input(shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print(model.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.9743 - val_loss: 0.1777\n",
      "Epoch 2/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9723 - val_loss: 0.1907\n",
      "Epoch 3/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.9704 - val_loss: 0.1904\n",
      "Epoch 4/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9731 - val_loss: 0.1887\n",
      "Epoch 5/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9710 - val_loss: 0.2131\n",
      "Epoch 6/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.9969 - loss: 0.0088 - val_accuracy: 0.9751 - val_loss: 0.1669\n",
      "Epoch 7/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9736 - val_loss: 0.1867\n",
      "Epoch 8/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 0.9983 - loss: 0.0071 - val_accuracy: 0.9740 - val_loss: 0.1771\n",
      "Epoch 9/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9764 - val_loss: 0.1735\n",
      "Epoch 10/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9714 - val_loss: 0.1995\n",
      "Epoch 11/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9739 - val_loss: 0.1845\n",
      "Epoch 12/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 0.9980 - loss: 0.0052 - val_accuracy: 0.9695 - val_loss: 0.2279\n",
      "Epoch 13/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9752 - val_loss: 0.1827\n",
      "Epoch 14/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9735 - val_loss: 0.1946\n",
      "Epoch 15/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9742 - val_loss: 0.2008\n",
      "Epoch 16/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9756 - val_loss: 0.1947\n",
      "Epoch 17/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9717 - val_loss: 0.2187\n",
      "Epoch 18/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9755 - val_loss: 0.1901\n",
      "Epoch 19/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9718 - val_loss: 0.1982\n",
      "Epoch 20/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9745 - val_loss: 0.2040\n",
      "Epoch 21/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.9985 - loss: 0.0065 - val_accuracy: 0.9762 - val_loss: 0.1991\n",
      "Epoch 22/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9739 - val_loss: 0.2109\n",
      "Epoch 23/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.9749 - val_loss: 0.2118\n",
      "Epoch 24/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9708 - val_loss: 0.2135\n",
      "Epoch 25/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9755 - val_loss: 0.1896\n",
      "Epoch 26/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9762 - val_loss: 0.2020\n",
      "Epoch 27/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.9997 - loss: 9.1124e-04 - val_accuracy: 0.9680 - val_loss: 0.2619\n",
      "Epoch 28/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9750 - val_loss: 0.2265\n",
      "Epoch 29/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9760 - val_loss: 0.2114\n",
      "Epoch 30/30\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.9998 - loss: 9.1683e-04 - val_accuracy: 0.9737 - val_loss: 0.2490\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer= 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28)\n",
    "\n",
    "model.fit(x_train, y_train, shuffle=True, validation_split=0.2, validation_data=None, epochs=30)\n",
    "\n",
    "model.save('digits.model.keras')\n",
    "\n",
    "saved_model = tf.keras.models.load_model('digits.model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "x_test = x_test.reshape(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = saved_model.predict(x_test)\n",
    "predicted_labels = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predicted_labels) + 1), \n",
    "    'Label': predicted_labels\n",
    "})\n",
    "\n",
    "results.to_csv('MLP_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
